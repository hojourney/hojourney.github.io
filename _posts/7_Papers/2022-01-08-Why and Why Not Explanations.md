---
layout: default
title: Why and Why Not Explanations
parent: Papers
nav_order: -20
last_modified_date: 2021-10-09
---


# Why and Why Not Explanations Improve the Intelligent Systems


## ê°„ëµí•œ ìš”ì•½

**Context-aware intelligent systems**ëŠ” ë‚´ì œëœ ì¸í’‹ê°’ì„ ì‚¬ìš©í•˜ê³  ì‚¬ìš©ìê°€ ì•Œê¸° ì–´ë ¤ìš´ ë³µì¡í•œ ê·œì¹™ê³¼ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì— ë”°ë¼ ì„ íƒì„ í•œë‹¤.

â†’ ê·¸ ê²°ê³¼, ì‹œìŠ¤í…œì˜ ëª…ë£Œí•¨ì´ ë¶€ì¡±í•˜ê²Œ ë˜ê³  ì´ëŠ” ì‚¬ìš©ìì˜ trust, satisfaction, ì‹œìŠ¤í…œì— ëŒ€í•œ acceptanceë¥¼ ë‚®ì¶˜ë‹¤.

â†’ ì‹œìŠ¤í…œì˜ ì„ íƒ ê³¼ì •ì— ëŒ€í•˜ì—¬ ìë™ìœ¼ë¡œ ì„¤ëª…ì„ ì œê³µí•˜ì—¬ ì™„í™” ê°€ëŠ¥

ì‹¤í—˜: ì°¸ê°€ìë“¤ì—ê²Œ ì‹œìŠ¤í…œì˜ ì‘ë™ê³¼ í•¨ê»˜ ë‹¤ì–‘í•œ ìë™ ìƒì„± ì„¤ëª…ì„ ì œê³µí•˜ê³  ì‹œìŠ¤í…œì— ëŒ€í•´ ì–¼ë§ˆë‚˜ ì´í•´í–ˆëŠ”ì§€ í™•ì¸ â†’ ì‹œìŠ¤í…œì´ ì™œ ê·¸ë ‡ê²Œ _í–‰ë™í–ˆëŠ”ì§€_ ë¬˜ì‚¬í•˜ëŠ” ì„¤ëª…ì€ ì´í•´ë¥¼ ë†’ì´ê³  ì‹ ë¢°ë„ë¥¼ ë†’ì˜€ë‹¤. â†’ ì‹œìŠ¤í…œì´ ì™œ ê·¸ë ‡ê²Œ _í–‰ë™í•˜ì§€ ì•Šì•˜ëŠ”ì§€_ ë¬˜ì‚¬í•˜ëŠ” ì„¤ëª…ì€ ì´í•´ë„ëŠ” ë‚®ì•˜ì§€ë§Œ ì ì ˆí•œ ì„±ê³¼ë¥¼ ë³´ì—¬ì£¼ì—ˆë‹¤. ~~ì–´ë–¤ performance?~~
<br><br><br>
## ìƒì„¸í•œ ì •ë¦¬

**Context-aware intelligent system**: ì‚¬ìš©ìì˜ í˜„ì¬ ìƒíƒœ(ë§¥ë½)ì— ë”°ë¼ ì ì‘í•˜ê³  ë§ì¶”ëŠ” ì‹œìŠ¤í…œ e.g., ì‚¬ìš©ìì˜ í™œë™, ìœ„ì¹˜, í™˜ê²½ì  ì¡°ê±´ì— ë”°ë¼

-   Calm computing: ì‚¬ìš©ìì˜ ê°œì… ì—†ì´ ì•”ë¬µì ìœ¼ë¡œ ì¸í’‹ ê°’ì´ ìˆ˜ì§‘ë˜ëŠ” ê²ƒ â†’ ì´ëŸ° ìš”ì†Œ ë•Œë¬¸ì— ì‚¬ìš©ìê°€ ì´í•´í•  ìˆ˜ ì—†ëŠ” ê³¼ì •ì´ ë°œìƒí•˜ê²Œ ë¨ (Intelligibility X = ì‚¬ìš©ìê°€ ì˜ˆì¸¡í•œ ê²ƒê³¼ ì‹œìŠ¤í…œì˜ í–‰ë™ì˜ mismatch)

[ì¶”ê°€ì  ê°œë…ë“¤]

-   Weiserâ€™s vision of ubiquitous computing: ì†Œí”„íŠ¸ì›¨ì–´ ê³µí•™ê³¼ í•˜ë“œì›¨ì–´ ê³µí•™, ì»´í“¨í„° ê³µí•™ì—ì„œ ì¼ì»«ëŠ” ì»´í“¨í„°ê°€ ì–¸ì œ ì–´ë””ì„œë“  ì‚¬ìš©ë  ìˆ˜ ìˆì„ ê²ƒì´ë¼ëŠ” ê²ƒ. (â‰  ë°ìŠ¤í¬íƒ‘)

â‡’ Automatically generated explanationsë¡œ í•´ê²° â‡’ decision making, recommender systemsì—ì„œ íš¨ê³¼ì (trust, acceptance ë†’ì•„ì§) e.g., Amazonâ€™s product recommender system, Pandoraâ€™s music recommender

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_1.png){: width="100%" height="100%"}
<br><br><br>
## Intelligibility

ë§ì€ ì—°êµ¬ë“¤ì´ ì„¤ëª…ì˜ ìƒì„±ê³¼ ì œê³µì— ì´ˆì ì´ ë§ì¶° ìˆì—ˆë‹¤. â†’ **Knowledge-based systems(KBS)** : Gregor & Benbasatì— ë”°ë¥´ë©´ reasoning trace(ì¼€ì´ìŠ¤ ë³„ ì¶”ë¡  ê³¼ì • ì œê³µ), justification(â€ì‹¬í™”ëœâ€ ë„ë©”ì¸ ì§€ì‹ì„ ë¶™ì´ëŠ”), strategic(ì‹œìŠ¤í…œì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì „ëµ), terminology(ìš©ì–´ ì •ì˜)ì˜ ì¹´í…Œê³ ë¦¬ë¡œ ì½˜í…ì¸ ë“¤ì´ êµ¬ë¶„ë  ìˆ˜ ìˆìŒ â†’ **Intelligent tutoring systems(ITS)**

**Context-aware systems**ëŠ” ì‚¬ìš©ìì˜ í˜¼ë€ì„ ì´ˆë˜(ëœ ì¹œìˆ™í•œ ì¸í„°í˜ì´ìŠ¤, ì‹œìŠ¤í…œì´ ë¬´ì—‡ì„ í•˜ëŠ”ì§€ ì´í•´ X, ì™œ ê·¸ë ‡ê²Œ í–ˆëŠ”ì§€ ì´í•´ X)

â†’ ì´ ì—°êµ¬ëŠ” **reasoning traces**ê°€ ë  ìˆ˜ ìˆëŠ” ì„¤ëª…ì— ëŒ€í•´ ì§‘ì¤‘

Reasoning traces ëŠ” ëŒ€ê°œ why & howì— ëŒ€í•œ ì§ˆë¬¸ì„ ì„¤ëª…í•˜ëŠ” ë°˜ë©´ ìƒˆë¡œìš´ ì‹œìŠ¤í…œì„ ì´ìš©í•˜ëŠ” end-usersê°€ ë¬¼ì„ ìˆ˜ ìˆëŠ” ì§ˆë¬¸ë“¤ì´ ì¶”ê°€ì ìœ¼ë¡œ ìˆë‹¤. â†’ 1. What: ì‹œìŠ¤í…œì´ ë¬´ì—‡ì„ í•˜ì˜€ëŠ”ê°€? â†’ 2. Why: ì‹œìŠ¤í…œì´ Wë¥¼ ì™œ í•˜ì˜€ëŠ”ê°€? â†’ 3. Why Not: ì‹œìŠ¤í…œì€ Xë¥¼ ì™œ í•˜ì§€ ì•Šì•˜ëŠ”ê°€? â†’ 4. What If: Yê°€ ì¼ì–´ë‚˜ë©´ ì‹œìŠ¤í…œì€ ë¬´ì—‡ì„ í•˜ëŠ”ì§€? â†’ 5. How To: í˜„ì¬ ìƒí™©ì„ ê³ ë ¤í•  ë•Œ ì‹œìŠ¤í…œì´ Zí•˜ê²Œ í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼í•˜ëŠ”ê°€?

### = 5 Intelligibility Questions

ê° ì§ˆë¬¸ì„ ì„¤ëª…í•˜ëŠ” ê²ƒì€,

### Intelligibility Type Explanations

Normanì€ Userì˜ ëª©í‘œì™€ ì‹œìŠ¤í…œ ìƒíƒœì˜ ì •ë³´ë¥¼ êµ¬ë¶„í•˜ëŠ” ë‘ê°€ì§€ ê°„ê·¹ì„ ë¬˜ì‚¬í•˜ì˜€ë‹¤.

â†’ 1 ~ 3ë²ˆì˜ ì§ˆë¬¸ì— ëŒ€í•œ ì„¤ëª…: **gulf of evaluation**(ì¸ì§€ëœ ê¸°ëŠ¥ì„±ê³¼ ì‚¬ìš©ìì˜ ì˜ë„, ì˜ˆìƒì˜ ë¶„ë¦¬) â†’ 4 ~ 5ë²ˆì˜ ì§ˆë¬¸ì— ëŒ€í•œ ì„¤ëª…: **gulf of execution**(ì‹œìŠ¤í…œìœ¼ë¡œ í•  ìˆ˜ ìˆëŠ” ê²ƒê³¼ ê·¸ê²ƒì— ëŒ€í•œ ì‚¬ìš©ìì˜ ì¸ì§€)

ì‚¬ëŒë“¤ì€ í˜„ì¬ ì¸í’‹ê³¼ ì¡°ê±´ì— ì•½ê°„ì˜ ë³€í™”ê°€ ìƒê¸°ë©´ ì–´ë–¤ ì¼ì´ ì¼ì–´ë‚ ì§€ ì•Œê³  ì‹¶ì–´ í•œë‹¤: Q4 ì‚¬ëŒë“¤ì€ íŠ¹ì • ìƒí™©ì´ë‚˜ ì¡°ê±´ì—ì„œ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ìœ¼ë ¤ë©´ ë¬´ì—‡ì„ ë°”ê¿”ì•¼í•˜ëŠ”ì§€ ì•Œê³ ì‹¶ì–´ í•œë‹¤: Q5

**ê´€ë ¨ ê¸°ì¡´ ì—°êµ¬**

Whyline(2004): Q2(**Why**) â†’ ì´ˆë³´ í”„ë¡œê·¸ë˜ë¨¸ë“¤ì´ ê°€ì§ˆ ìˆ˜ ìˆëŠ” Intelligibility questionsì— ëŒ€í•œ ì„¤ëª… ì—°êµ¬

Crystal application framework(2006): Q3(**Why Not**) â†’ ë°ìŠ¤í¬íƒ‘ ì‚¬ìš©ìê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” Intelligibility questionsì— ëŒ€í•œ ì„¤ëª… ì—°êµ¬

â‡’ í•˜ì§€ë§Œ ì´ ì„¤ëª… ì¢…ë¥˜ì— ëŒ€í•œ ìœ ìš©ì„±ì´ ë¹„êµë˜ì§€ ì•Šì•˜ìŒ

**KBS(Knowledge-based systems)** â†’ Why, Why Not, How To ì§ˆë¬¸ë“¤ì„ ìœ„í•œ reasoning trace explanations e.g., MYCIN (í•˜ì§€ë§Œ ì§ˆë¬¸ë“¤ ì‚¬ì´ì˜ íš¨ê³¼ì— ëŒ€í•œ ë¹„êµëŠ” ì—†ì—ˆìŒ)

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_2.png){: width="100%" height="100%"}
\: ì¸í„°ë™ì…˜ì´ ì‰½ê³  ìì—°ìŠ¤ëŸ½ë„ë¡ ë…¸ë ¥, ì§ˆë¬¸ì´ ì‹ ì¤‘ì„ ê¸°í•´ì„œ ì‘ì„±ëœ ê²ƒ(multiple choice ì§ˆë¬¸ì²˜ëŸ¼ ì¬ë¯¸ ì—†ê²Œ ë§Œë“¤ì§€ ì•Šê¸° ìœ„í•´ì„œ)

í›„ê¸° ë…¼ë¬¸ë“¤ë„ reasoning traceë¥¼ ìœ„í•œ íƒ€ë‹¹í•œ ì„¤ëª…ì„ ì œê³µí•˜ëŠ” ê²ƒê³¼ problem-solving ì „ëµì„ ì„¤ëª…í•˜ëŠ” ê²ƒì—ë§Œ ì§‘ì¤‘.

ì´ ë…¼ë¬¸ì€ **Reasoning trace explanations**ì— ì§‘ì¤‘(context-aware ì‹œìŠ¤í…œì´ ê¹Šì€ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì„ íƒì„ ì¶”ë¡ í•˜ëŠ” ê²ƒì— ëŒ€í•œ ê²ƒì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì—) â†’ Why, Why Not, What If, How To ì¤‘ ì–´ë–¤ ì§ˆë¬¸ ìœ í˜•ì´ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ë„ì›€ì´ ë˜ëŠ”ê°€(Inputê³¼ Outputì„ ë¶„ëª…í•˜ê²Œ ë³´ì—¬ì£¼ê¸° ë•Œë¬¸ì— Whatì€ ì œì™¸)
<br><br><br>
## ê°€ì„¤

ìš°ì„  ì„¤ëª…ì˜ ì¢…ë¥˜ê°€ ë‹¤ë¥´ë©´ ì‚¬ìš©ì ê²½í—˜(ì‹œìŠ¤í…œì— ëŒ€í•œ ì´í•´ë„, trustì— ëŒ€í•œ ì¸ì‹)ì´ ë‹¤ë¥¼ ê²ƒì´ë¼ê³  ìƒê°í–ˆë‹¤.

**Whyì— ëŒ€í•œ ê°€ì„¤: Why ì„¤ëª…ì€ ì‹œìŠ¤í…œ í–‰ë™ì˜ ì›ì¸ì„ ì¶”ì í•˜ëŠ” ê²ƒì— ë„ì›€ì„ ì£¼ê³  ë”°ë¼ì„œ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•  ê²ƒì´ë‹¤**

<aside> ğŸ’¡ â†’ H1: _Why_ explanations will improve user experience over having no explanations (_None_).

</aside>

**Why Notì— ëŒ€í•œ ê°€ì„¤: Why ì„¤ëª…ê³¼ ë¹„ìŠ·í•œ ì˜í–¥ì„ ê°€ì§ˆ ê²ƒì´ì§€ë§Œ, Why Not ì„¤ëª…ì€ ì‚¬ìš©ìê°€ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ì—†ì„ ê²ƒì´ë‹¤. WhyëŠ” reasoning traceê°€ í•˜ë‚˜ í˜¹ì€ ì ê² ì§€ë§Œ, Why Notì€ ì—¬ëŸ¬ traceê°€ ìˆì„ ê²ƒì´ê¸° ë•Œë¬¸ì—.**

<aside> ğŸ’¡ â†’ H2: _Why Not_ explanations will (a) improve user experience over having no explanations, but (b) will not perform as well as _Why_ explanations.

</aside>

**How To & What If ì— ëŒ€í•œ ê°€ì„¤: How To & What If ì§ˆë¬¸ì€ ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œë¥¼ ì •ì˜í•˜ëŠ” ì˜ˆì‹œì— ì˜ì¡´í•˜ê¸° ë•Œë¬¸ì—(?) ì¸í„°ë™í‹°ë¸Œí•˜ê³  ì—­ë™ì ì´ì–´ì•¼ í•œë‹¤. ì´ëŸ° ì„¤ëª…ì€ ì„¤ëª…ì´ ì—†ëŠ” ê²ƒë³´ë‹¤ëŠ” ìœ ìš©í•  ê²ƒì´ë‹¤. í•˜ì§€ë§Œ ì´ˆë³´ ì‚¬ìš©ìëŠ” ì‹œìŠ¤í…œì— ìµìˆ™í•˜ì§€ ì•Šì„ ê²ƒì´ë¯€ë¡œ ì¢‹ì§€ ì•Šì€ ì˜ˆì‹œë¥¼ ê³ ë¥¼ ê²ƒì´ë©° Why ë³´ë‹¤ íš¨ê³¼ê°€ ì¢‹ì§€ ì•Šì„ ê²ƒì´ë‹¤.**

<aside> ğŸ’¡ â†’ H3: _How To_ or _What If_ explanations will (a) improve user experience over having no explanations (_None_), but (b) will not perform as well as _Why_ explanations.

</aside>

## Intelligibility Testing Infrastructure

ì‚¬ìš©ìëŠ” context-aware applicationì˜ schematic, functional _intelligible_ systemì„ ì‚¬ìš©í•˜ê²Œ ëœë‹¤.

â†’ **a set of inputs (e.g., Temperature, Humidity)** â†’ **uses a model (e.g., Decision-tree)** â†’ **produce a single output (e.g., Rain Likely, or Rain Unlikely)**

â‡’ **ì‚¬ìš©ìëŠ” inputs, outputs, explanations (or none) depending on intelligibility type**ë¥¼ ë°›ê²Œëœë‹¤.

## System Implementation

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_3.png){: width="100%" height="100%"}

ì‚¬ìš©ìëŠ” Input values listedë¥¼ ë³´ê²Œë˜ê³  _**Execute**_ ë²„íŠ¼ì„ ëˆ„ë¥¸ë‹¤ â†’ ì‹œìŠ¤í…œì€ Outputì„ _**Generates**_ í•œë‹¤ â†’ ì˜ˆì‹œë¥¼ ë°°ìš°ê³  ë‚˜ì„œ _**Next Example**_ì„ í´ë¦­í•œë‹¤. â†’ _**Explanation condition**_ì— ë”°ë¼ ì‚¬ìš©ìëŠ” ì˜ˆì‹œì— ëŒ€í•œ ì„¤ëª…ì„ ë°›ê²Œëœë‹¤. (ì‚¬ìš©ìê°€ ìš”êµ¬ í•  ë•Œë§Œ ë³´ì—¬ì§€ëŠ” ê²½ìš°ë„ ìˆìŒ?)

**Sensor-based context-aware systems** ì‚¬ìš©

â†’ multi sensors(ìˆ˜ì¹˜ê°’)ì˜ Input ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ decisionì„ ë§Œë“¬. í•˜ì§€ë§Œ Inequality-based(~~?~~) rulesë¥¼ ì‚¬ìš©í•˜ì—¬ outputì„ ê³„ì‚°(outputì„ 2 í´ë˜ìŠ¤ ì¤‘ 1ê°œë¡œ ê²°ì •)

ì•„ë˜ì²˜ëŸ¼ 2 Input ê°’ì„ ê³ ë ¤í•˜ì—¬ 2 Inequality rulesë¥¼ ì •í•œë‹¤.

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_4.png){: width="100%" height="100%"}

ì‚¬ëŒë“¤ì´ ë„ë©”ì¸ ì§€ì‹ì´ ë¶€ì¡±í•´ì„œ ì‹œìŠ¤í…œì— ëŒ€í•œ ì´í•´ë„ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ë„ ìˆìœ¼ë‹ˆ ì •ìˆ˜ë¡œ ëª¨ë“  ìˆ˜ì¹˜ê°’ì„ ëŒ€ì²´í•˜ì˜€ìŒ(e.g., ë¬´ê²Œë¥¼ ë“¤ ë•Œ ì²´ì˜¨ì´ 36.8ë„ì—ì„œ 38.3ë„ë¡œ ì˜¬ë¼ê°ˆ ìˆ˜ ìˆëŠ” ê±¸ ì•„ëŠ” ê²ƒ ê°™ì€ ë„ë©”ì¸ ì§€ì‹) â†’ Body Temperature (1 to 10), Heart Rate & Pace (1 to 5)

Context-aware applicationsì—ì„œëŠ” MLì´ ë§ì´ ì‚¬ìš©ë˜ê³ , ì´ ì‹¤í—˜ë„ ë§ˆì°¬ê°€ì§€ë¡œ ì‚¬ìš©.

â†’ Decision trees & Naive Bayes ì¤‘ **Decision trees** ì‚¬ìš©(ì–˜ë„¤ê°€ ê·¸ë‚˜ë§ˆ explainable & transparentí•¨, SVMì´ë‚˜ Neural NetworksëŠ” Interpretable X)

â†’ ëª¨ë“  inputsì˜ ìˆœì—´ ì¤‘ì—ì„œ 250 ê²½ìš°ë¥¼ í•™ìŠµí•˜ì—¬ output valueë¥¼ ê²°ì •í•˜ê¸° ìœ„í•´ decision tree ëª¨ë¸ í˜•ì„±

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_5.png){: width="100%" height="100%"}
<br><br><br>
## Decision Tree Explanations

Decision TreeëŠ” 4ê°€ì§€ intelligibility type questionsì— ëŒ€í•œ ì„¤ëª…ì„ ì œê³µí•˜ê¸°ì— ì í•©í•˜ë‹¤. ì•„ë˜ì˜ í‘œë¥¼ í†µí•´ ì„¤ëª…ì´ ì–´ë–»ê²Œ ë§Œë“¤ì–´ì¡Œë‚˜ ì•Œ ìˆ˜ ìˆë‹¤.

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_6.png){: width="100%" height="100%"}

## METHOD: Experiments

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_7.png){: width="100%" height="100%"}
\: Activity recognition of exercising

Experiment 1ì„ í†µí•´ Why, Why Not, and the control condition with no explanationsì˜ intelligibility explanationsë¥¼ ì‹¤í—˜. (í”¼ì‹¤í—˜ìì˜ ë„ë©”ì¸ ì§€ì‹ ë•Œë¬¸ì— ê²°ê³¼ í•´ì„ì´ í˜ë“¤ì—ˆìŒ)

Experiment2ëŠ” Abstractí•œ Domainì„ ì‚¬ìš© â†’ Why, Why Not, How To, What If 4ê°€ì§€ì˜ Intelligibility type questions ì„¤ëª… ì œê³µ

### Study Procedure

1.  Learning Section: ì‚¬ìš©ìê°€ ì‹œìŠ¤í…œê³¼ ìƒí˜¸ì‘ìš©í•˜ê³  ì‹œìŠ¤í…œì´ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ ë°°ì›€
2.  Fill-in-the-Blanks Test Section: í”¼ì‹¤í—˜ìì˜ ì‹œìŠ¤í…œì— ëŒ€í•œ ì´í•´ í™•ì¸-1
3.  Reasoning Test Section: í”¼ì‹¤í—˜ìì˜ ì‹œìŠ¤í…œì— ëŒ€í•œ ì´í•´ í™•ì¸-2
4.  Survey Section: í”¼ì‹¤í—˜ìì—ê²Œ ì‹œìŠ¤í…œì´ ì–´ë–»ê²Œ ë™ì‘í–ˆëŠ”ì§€ ì„¤ëª…í•˜ë„ë¡ ìš”ì²­(ì‹œìŠ¤í…œì˜ ë¡œì§ì— ëŒ€í•´ í”¼ì‹¤í—˜ìê°€ ì–¼ë§ˆë‚˜ í•™ìŠµí–ˆëŠ”ì§€ í‰ê°€í•˜ê¸° ìœ„í•¨)í•˜ê³  ì„¤ëª…ì— ëŒ€í•œ ì¸ì‹ì— ëŒ€í•´ í‰ê°€í•˜ê³  ì‹œìŠ¤í…œì— ëŒ€í•œ ì´í•´ë„(understandability), ì‹ ë¢°ë„(trust), ìœ ìš©ì„±(usefulness)ì— ëŒ€í•´ í‰ê°€í•˜ë„ë¡ ìš”êµ¬

**[ Learning Section ]**

-   ì¸í’‹ê³¼ ì•„ì›ƒí’‹ì´ ìˆëŠ” 24ê°œ ì˜ˆì‹œë¥¼ ê° ì˜ˆì‹œë‹¹ ì ì–´ë„ 8ì´ˆ ì´ìƒ ë³´ê²Œ ëœë‹¤.(ê° ì‚¬ìš©ìëŠ” ëª¨ë‘ ê°™ì€ ìˆœì„œë¡œ ì˜ˆì‹œë¥¼ ë³¸ë‹¤.)
-   ì‹¤í—˜ ì¡°ê±´ì— ë”°ë¼ ì„¤ëª…ì´ ì œê³µëœë‹¤. Learning Sectionì—ì„œë§Œ ì„¤ëª…ì´ ì£¼ì–´ì§.
-   ì‚¬ìš©ìëŠ” ì‹œìŠ¤í…œì´ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ ë°°ì›Œì•¼ í•œë‹¤ê³  ê³¼ì—…ì´ ì£¼ì–´ì§€ë©° ë…¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¥¼ í•  ìˆ˜ ìˆë‹¤. Learning Sectionì„ ë§ˆì¹˜ë©´ ì‚¬ìš©ìëŠ” ë…¸íŠ¸ë¥¼ ë³´ë©° í•™ìŠµí•  ìˆ˜ ìˆëŠ” ì‹œê°„ì´ ì£¼ì–´ì§„ë‹¤.

**[Fill-in-the-Blanks Test Section]**

-   ì‚¬ìš©ìëŠ” ë¹ˆì¹¸ì´ ìˆëŠ” ì˜ˆì œì˜ ë¹ˆì¹¸ì„ ì±„ìš°ëŠ” ê³¼ì—…ì„ ìˆ˜í–‰í•˜ê²Œ ëœë‹¤. (15 ê²½ìš°ê°€ ìˆëŠ”ë°, Body Temperature 3ê°œ, Heart Rate 3ê°œ, Pace 4ê°œ, ê²°ê³¼ ë¹ˆì¹¸ 5ê°œ) â†’ í”¼ì‹¤í—˜ì ëª¨ë‘ ê°™ì€ ìˆœì„œ
-   ë¹ˆì¹¸ì„ ì±„ìš°ê³  ë‚˜ì„œ ì™œ ê·¸ë ‡ê²Œ ìƒê°í–ˆëŠ”ì§€ ì´ìœ ê°€ ë¬¼ì–´ì§„ë‹¤.
-   ë‹µì€ ì•Œ ìˆ˜ ì—†ê³ , ì¶”ê°€ì ì¸ ì„¤ëª…ë„ ì£¼ì–´ì§€ì§€ ì•ŠëŠ”ë‹¤.

**[Reasoning Test Section]**

-   3ê°€ì§€ ë³µì¡í•œ ì˜ˆì œ(outputì´ ì™œ ë‚˜ì˜¨ ê²ƒ ê°™ì€ì§€ ì´ìœ  ì„¤ëª…í•˜ê¸°)ê°€ ì£¼ì–´ì§„ë‹¤. â†’ ì´ì „ì— ë§ˆì£¼í•˜ì§€ ëª»í•œ ìƒˆë¡œìš´ ì˜ˆì œ â†’ í”¼ì‹¤í—˜ì ëª¨ë‘ ê°™ì€ ìˆœì„œ
-   ì´í•´ë„ê°€ ë†’ìœ¼ë©´ trustê°€ ë†’ì€ì§€ í™•ì¸í•˜ê¸° ìœ„í•´, ê·¸ë“¤ì´ ì‹œìŠ¤í…œì˜ ê²°ê³¼ë¥¼ ì–¼ë§ˆë‚˜ ì‹ ë¢°í•˜ëŠ”ì§€ ë¬¼ì–´ì§„ë‹¤.
-   ë‹µì€ ì•Œ ìˆ˜ ì—†ê³  ì¶”ê°€ì ì¸ ì„¤ëª…ë„ ì£¼ì–´ì§€ì§€ ì•ŠëŠ”ë‹¤.

**[Survey Section]**

-   Self-report information: ì „ë°˜ì ìœ¼ë¡œ ì‹œìŠ¤í…œì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ëŠ”ì§€, ëŠë¼ëŠ”ì§€ ë” ìì„¸í•œ ì„¤ëª…ì„ ìœ„í•´(e.g., ë©˜íƒˆëª¨ë¸ ëŒì–´ë‚´ê¸°, ì‹œìŠ¤í…œê³¼ ì„¤ëª…ì„ trust í–ˆëŠ”ì§€, understood í–ˆëŠ”ì§€)

### Measures

**Types of intelligibility explanations** â†’ better understanding the system â†’ better task performance, improved perception of the system, improved trust in the system output

**User understanding**

â†’ correctness(Fill-in-the-Blanks) & detail of the reasons(Reasoning Test with why and why not questions, mental model in the survey)

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_8.png){: width="100%" height="100%"}
\: coded reasons

**Task performance** â†’ task completion time(Learning sectionì˜ ë°°ìš°ëŠ” ì‹œê°„, Fill-in-the-Blanksì—ì„œ ì±„ìš°ëŠ”ë° ê±¸ë¦° ì‹œê°„), Fill-in-the-Blanks Test inputs and output answer correctness

**User Understanding**

â†’ Surveyì—ì„œ mental model í™•ì¸, Whyì²˜ëŸ¼ coded ë¨

**User Perception**

â†’ 16 Likert-scale questions of system and explanation perceptions 10: Understood System, Found System Confusing, Liked System/Found it useful 6: Explanations Difficult, Explanations Useful, Understood Explanations.

**User Trust**

Reasoning Testsì˜ Why & Why not questions â†’ coded(Table 1)

-   trustê°€ 5-point Likert-scaleë¡œ ê¸°ë¡
<br><br><br>
## Experiment 1

### Experiment 1: H1(Why vs None), H2(Why Not vs None & vs Why)

Wearable device(Body Temperature, Heart Rate, Walking/running Pace) â†’ Exercising O/X (ë¬´ê²Œ ë“¤ê¸°, ë›°ê¸°)

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_9.png){: width="100%" height="100%"}

### Experiment 1 - Results

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_10.png){: width="100%" height="100%"}

ì‚¬ëŒë“¤ì´ ê·¸ë“¤ì˜ ì´í•´ë¥¼ ì ìš©í•˜ëŠ” ëŠ¥ë ¥ì„ í™•ì¸í•˜ê¸° ìœ„í•´ ëª‡ê°œ ë§ì·„ëŠ”ì§€ë¥¼ ì´ìš©

**Intelligibility types â†’ ëª‡ ê°œë‚˜ ë§ì·„ëŠ”ì§€(DV)**

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_11.png){: width="100%" height="100%"}

ì‚¬ëŒë“¤ì´ ìì‹ ì˜ ì´í•´ë¥¼ formalize í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë³´ê¸° ìœ„í•´ Inequality or better (0 or 1), Partially or Fully Correct (0 or 1), Fully Correct (0 or 1)

Condition â†’ Reason coding(DV)

: providing explanations â†’ more correct answers(but Why & Why Not ì°¨ì´ X)

ìƒì„¸í•˜ê²Œ

Partially Correct: Why & Why Not ëª¨ë‘ê°€ None ë³´ë‹¤ ë†’ìŒ Fully Correct: Whyê°€ None & Why Not ëª¨ë‘ ë³´ë‹¤ ë†’ìŒ í•˜ì§€ë§Œ, Why & Why Not ì‚¬ì´ì˜ Significant í•œ ì°¨ì´ëŠ” X

Trust: Why > None, Why Notì€ X

Surveyì—ì„œëŠ” Significantí•œ ì°¨ì´ X

### Experiment 1 - Discussion and Implications

-   ì „ë°˜ì ìœ¼ë¡œ Trustê°€ ë‚®ì€ ê²ƒì€ â€˜naturalâ€™í•˜ê²Œ ë³´ì´ì§€ ì•Šì•„ì„œ ì¼ ìˆ˜ë„ ìˆë‹¤(e.g., ì²´ì˜¨ì€ ë†’ì€ë° ì†ë„ê°€ ë‚®ìœ¼ë©´ Not Exercisingì¸ ê²ƒ)
-   ì„¤ëª… O â†’ understanding ë†’, trust ë†’, ì‹œìŠ¤í…œì˜ ê²°ê³¼ì— ëŒ€í•œ agree ë†’
-   Whyì—ì„œ ì¼ë¶€ í”¼ì‹¤í—˜ìë“¤ì´ ì¸í’‹ ê°’ì´ Exercising ê³¼ ì–´ë–»ê²Œ ê´€ë ¨ë¼ì•¼ í•˜ëŠ”ì§€ ë§í•˜ê¸°ë„ í–ˆê³ , ì¸í’‹ ê°’ì„ â€œHighâ€ë‚˜ â€œLowâ€ë¡œ í•˜ê¸°ë„ í–ˆë‹¤. â†’ prior knowledgeê°€ ì´í•´ì— ë“œëŠ” ë…¸ë ¥ì„ ì¤„ì—¬ì¤„ ê²ƒì„ì„ ì•Œ ìˆ˜ ìˆìŒ.
<br><br><br>
## Experiment 2

### Experiment 2 - H3(How to & What If vs None, why)

Explanations typesì˜ effectiveness ë¹„êµ(ì•„ë˜ì˜ í…Œì´ë¸”ì— ë”°ë¼ êµ¬ë¶„)

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_12.png){: width="100%" height="100%"}

### Experiment 2 - Method

1ê³¼ ê°™ì€ ê³¼ì •ì´ì§€ë§Œ ì¼ë¶€ ì¸í’‹ë“¤ì´ A, B, Cë¡œ ë˜ì–´ìˆê³ , ì•„ì›ƒí’‹ ê°’ì´ a, bë¡œ ë˜ì–´ìˆë‹¤.

**What If**

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_12.png){: width="100%" height="100%"}

**How To**

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_13.png){: width="100%" height="100%"}

### Experiment 2 - Results

Why, Why Not ì¡°ê±´ì´ None, What If, How To ì¡°ê±´ë³´ë‹¤ â†’ ì •ë‹µ ìˆ˜ ë§ì•˜ë‹¤(Fill-in-the-Blanks tests), ì´ìœ  ì ì ˆ, ì´í•´ë„ ë†’

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_14.png){: width="100%" height="100%"}
\: Participants in the Why and Why Not conditions had an accuracy of 80.0% and 74.2%, respectively, compared to 61.7% for the None condition

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_15png){: width="100%" height="100%"}

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_16.png){: width="100%" height="100%"}
\: the self-reports of understanding for Why and Why Not were 3.14 and 2.79, respectively

![ì´ë¯¸ì§€](../../assets/images/posts/20220108_17.png){: width="100%" height="100%"}

### Experiment 2 - Discussion and Implications

Why & Why Not â†’ understanding, trust, task performance í–¥ìƒ

Why ì„¤ëª… ì´ Why Not ë³´ë‹¤ ì •í™•í•œ ì´í•´ë¥¼ ë„ì›€(ë‹¨ìˆœíˆ ë’¤ì§‘ì€ ê±´ë°ë„), fewer correct answer rules, extraneous inputs and rules

â‡’ Why Not ì´ ë‘ ruleì„ í•©ì³ ìƒê°í•˜ì§€ ì•Šê³  seperatelyí•˜ê²Œ ìƒê°í•¨. reasoning traceë§Œ í•™ìŠµí•œ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŒ.(Why Notì—ëŠ” â€œbutâ€ â€œnotâ€ì´ ë“¤ì–´ìˆì–´ì„œ ê·¸ëŸ° ê±¸ ìˆ˜ ìˆë‹¤, ë” ë§ì€ mental effort í•„ìš”)

â‡’ Whyë¥¼ ë¨¼ì € ì œê³µí•˜ê³  Why Notì„ ì œê³µí•´ì•¼í•¨. (How to, What ifëŠ” ë¹„íš¨ìœ¨ì ì´ì§€ë§Œ executeí•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¨ëŠ” ê³¼ì—…ì—ì„œëŠ” íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŒ.)
<br><br><br>
## General Discussion

-   Experiment 1ì—ì„œì˜ mental modelì´ 2ë³´ë‹¤ ëœ ì •í™•í–ˆë‹¤. â†’ prior knowledgeê°€ ìƒê¸°ê³  ~~ì„¤ëª…ì— ì§‘ì¤‘í•˜ì§€ ì•Šì€ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŒ?~~

â‡’ ì‹¤ìƒí™œ ì„œë¹„ìŠ¤ì—ì„œ ì´ëŸ° ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ. ê²ªìœ¼ë©° prior knowledgeê°€ ìƒê¸°ê³  ì§‘ì¤‘í•´ì„œ ì„¤ëª…ì„ ë³´ì§€ ì•ŠëŠ”

â†’ ëŒ€ì•ˆ1: knowledge-based systems communityì—ì„œ ë°°ìš°ê²Œ í•  ìˆ˜ ìˆìŒ â†’ ëŒ€ì•ˆ2: deeper justification explanation ì œê³µ(ì™œ ì¼ìƒì—ì„œ ì´í•´í•œ ê²ƒê³¼ ë‹¤ë¥¸ì§€)

â‡’ prior knowledgeê°€ ì—†ëŠ” ì‚¬ëŒí•œí…Œë„ ë„ì›€ì´ ë¨

-   ì‹¤ì œ ìƒí™©ì—ì„œëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆìŒ(ì•„ë˜ì™€ ê°™ì€ ê²ƒì´ ë‹¤ë¤„ì§€ì§€ ì•Šì•˜ìŒ) â†’ ì‚¬ìš©ìëŠ” ì´í•´ë¥¼ ëª»í•˜ê² ì„ ë•Œ Whyë¥¼ ë¬¼ì–´ë³¼ ê²ƒì´ê³ , íŠ¹ì • ê²°ê³¼ë¥¼ ì˜ˆìƒí–ˆìœ¼ë‚˜ ê·¸ê±¸ ì–»ì§€ ëª»í–ˆì„ ë•Œ Why Notì„ ë¬¼ì–´ë³¼ ê²ƒì´ë‹¤. â†’ ì´ ì‹¤í—˜ì—ì„œ Why Notì´ ëœ íš¨ê³¼ì ìœ¼ë¡œ ë³´ì˜€ì–´ë„ Why Notì´ ì„ í˜¸ë  ìˆ˜ ìˆë‹¤.
-   ì‹¤ì œ context-aware systemsì€ ë” ë³µì¡í•  ìˆ˜ ìˆë‹¤. â†’ ëŒ€ì•ˆ: ì„¤ëª…ì„ ê°„ì†Œí™” í•˜ì—¬ ì „ë‹¬ â†’ ë°°ìš°ëŠ” ì‹œê°„ì„ ì§§ê²Œ í•˜ê¸°: ì²˜ìŒì—” ê¸´ ì„¤ëª… ì œê³µí•˜ê³  ì ì  ì„¤ëª…ì´ ê°„ì†Œí™” ë¨.
-   ì‚¬ìš©ìê°€ ì„¤ëª…ì„ ì›í•  ë•Œë§Œ ë°›ê³  ì‹¶ì„ ìˆ˜ë„ ìˆë‹¤.(ë¹ˆë„ë¥¼ ì •í•˜ê²Œ í•˜ê¸°)
<br><br><br>
## Conclusions

Context-aware applicationsì—ì„œ Novice usersì—ê²Œ Reasoning trace explanationsë¥¼ ì œê³µí•˜ëŠ” ê²ƒì€(íŠ¹íˆ Why) understanding ê³¼ trustë¥¼ ë†’ì¸ë‹¤.


> Reference<br>
> Lim, B. Y., Dey, A. K., & Avrahami, D. (2009, April). Why and why not explanations improve the intelligibility of context-aware intelligent systems. InÂ _Proceedings of the SIGCHI conference on human factors in computing systems_Â (pp. 2119-2128).

